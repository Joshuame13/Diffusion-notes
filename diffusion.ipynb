{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to learn how to code a diffusion model. I'll use the following paper: https://arxiv.org/abs/2011.13456.\n",
    "\n",
    "The only real assumption which we make is that we have access to data which follows some distribution. The goal is to sample from this distribution.\n",
    "\n",
    "The basic idea is as follows. Given a (vector-valued) probability distribution, we can define a stochastic process whose initial conditions are sampled according to this distribution, and whose evolution is governed by the SDE\n",
    "$$\n",
    "dx = f(x, t)\\, dt + g(t) \\,dw,\n",
    "$$\n",
    "where $w$ is a standard Brownian motion and time ranges from $0$ to $T$. One can consider the case where $f$ and $g$ are matrix-valued and are both allowed to depend on $x$ as well as $t$, but we will just need the scalar case. If the marginal density of this stochastic process at time $t$ is given by $p_t$, then one can show that the time-reversal of this process also follows a (backwards-time) SDE:\n",
    "$$\n",
    "dx = (f(x, t) - g^2(t) \\nabla_x \\log p_t(x) )\\,dt + g(t) \\,d \\overline w,\n",
    "$$\n",
    "where $\\overline w$ is a Brownian motion when time runs backwards. The conclusion of this is that, if you know $f, g, \\nabla_x \\log p_t(x)$, and $p_T$, then you can numerically simulate the backwards SDE to sample from $p_0$. Typically, the setup is such that $p_0$ is the distribution we wish to sample from and $p_T$ is known and easy to sample from. This is usually accomplished by choosing $f$ and $g$ such that the evolution of the forward SDE converges to (at least very close to) a standard Gaussian, regardless of the initial condition. This leaves $\\nabla_x \\log p_t(x)$ (for all $t$) as the only unknown piece of the puzzle. This is the so-called score function, which is the critical ingredient needed to sample from the backwards SDE.\n",
    "\n",
    "There is also an associated probability flow ODE which has the property that, if the initial conditions are chosen according to $p_0$, then the marginal distributions of the process at time $t$ exactly match the marginal distributions of the SDE at time $t$, although the trajectories are different. So by sampling from $p_T$ and simulating the ODE backwards (which requires no more work than simulating it forwards), once can sample from $p_0$. The ODE is given by\n",
    "$$\n",
    "dx = (f(x, t) - g^2(t) \\nabla_x \\log p_t(x) )\\,dt.\n",
    "$$\n",
    "Again, the only missing ingredient is the score function $\\nabla_x \\log p_t(x)$.\n",
    "\n",
    "From this, we see that, apart from choosing $f$ and $g$, there are essentially two steps to training and doing inference with a diffusion model: learning the score function, and numerically solving either an SDE or ODE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical machine learning approach is to use a neural network $s_\\theta(x, t)$ to approximate $\\nabla_x \\log p_t(x)$. The neural network must be a function of $x$ and $t$, as the score function is, and is parameterized by $\\theta$. The loss function is going to be weighted sum of\n",
    "$$\n",
    "\\| s_\\theta(x, t)- \\nabla_x \\log p_t(x)\\|^2\n",
    "$$\n",
    "evaluated at various choices of $x$ and $t$ (the norm is the $L^2$ norm, so this is the sum of squared errors). The exact weighting and choice of evaluation points can be considered a hyperparameter. It's also worth noting that $x$ and $t$ must be chosen in a way that makes evaluating $\\nabla_x \\log p_t(x)$ relatively easy. Indeed, it certainly must be difficult to evaluate it at arbitrary $x$ and $t$: if this were easy, there would be no need to learn a function $s_\\theta(x, t)$ approximating it.\n",
    "\n",
    "In general, working with the marginal density $p_t(x)$ is intractable, but the *conditional* marginal density, conditioned on initial value $x(0)$ of the SDE, may be easy to work with. We denote the conditional marginal density at time $t$, conditioned on the initial value $x(0)$, as $p_{0t}(x|x(0))$. In other words, $p_{0t}$ is the *transition kernel* from time $0$ to time $t$ of the stochastic process. If the choice of $f$ and $g$ are sufficiently nice, then this conditional marginal density is that of a Gaussian distribution whose mean and variance are a function of $x(0)$ and $t$. And the gradient of the log of this density is very easy to work with. \n",
    "\n",
    "I don't understand exactly the reasoning for the following. For fixed $t$, we want to minimize $\\mathbb E_{p_t(x)} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_t(x)\\|^2$, where the notation $\\mathbb E_{p_t(x)}$ means taking the expectation when $x$ is distributed according to $p_t(x)$. Since we know how to work with $p_{0t}(x | x(0))$ but not $p_t(x)$, we can instead minimize \n",
    "$$\n",
    "\\mathbb E_{p_0(x)} \\mathbb E_{p_{0t}(x | x(0))} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2.\n",
    "$$\n",
    "It is not obvious to me why minimizing this expression, where $p_t(x)$ has been replaced by $p_{0t}(x | x(0))$ (and a conditional expectation inserted), is equivalent to minimizing the original. It is, however, obvious that this problem is much more tractable. Lastly, we need to incorporate all time steps, so we can define our loss function as\n",
    "$$\n",
    "L(\\theta) = \\mathbb E_t \\lambda(t) \\mathbb E_{p_0(x)} \\mathbb E_{p_{0t}(x | x(0))} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2,\n",
    "$$\n",
    "where $\\lambda(t)$ is a nonnegative function which determines the relative weights of the loss at different times, and $\\mathbb E_t$ has $t$ uniformly distributed between $0$ and $T$. Of course, we must take these expectations numerically. A simple scheme to do this is to sample $t$ uniformly, sample $x(0)$ from the data, sample $x$ from $p_{0t}(x|x(0))$, and evaluate $\\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2$ at this point. Average this over many such samples to get an estimate of $L(\\theta)$ which can be used for optimization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, things have been completely general. Let's choose specific hyperparameters so that we can simplify things further. Notably, we need to know $\\nabla_x \\log p_{0t}(x | x(0))$ to be able to do anything. We set $T=1$, so that $t$ ranges from $0$ to $1$, and we make the following choice of $f$ and $g$:\n",
    "\\begin{align*}\n",
    "f(x, t) &= \\beta(t),\\\\\n",
    "g(t) &= \\sqrt{\\beta(t)},\\\\\n",
    "\\end{align*}\n",
    "This is the continuous-time analog of the discrete-time *denoising diffusion probabilistic modeling* approach. It remains to choose $\\beta(t)$. We choose \n",
    "$$\\beta(t) = \\beta_\\text{min} + t(\\beta_\\text{max} - \\beta_\\text{min}).$$\n",
    "So $\\beta(t)$ moves linearly from $\\beta_\\text{min}$ to $\\beta_\\text{max}$. And we will choose $\\beta_\\text{min}=0.1$, $\\beta_\\text{max}=20$. These are simply the choices made in the paper I am following, and I do not have any extra insight as to why these choices are are made. The main paper gives the following reference for how the mean and variance of the transition kernel can be computed: Applied stochastic differential equations, volume 10, by Simo Sarkka and Arno Solin.\n",
    "We can obtain the following transition kernels: $p_{0t}(x|x(0))$ is a Gaussian distribution with mean and variance \n",
    "\\begin{align*}\n",
    "\\mu(x(0), t) &= x(0) \\, \\exp\\left(-\\frac 1 4 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - \\frac 1 2 t \\beta_\\text{min}\\right), \\\\\n",
    "\\sigma(x(0), t)^2 &= 1 - \\exp \\left(-\\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - t \\beta_\\text{min}  \\right).\n",
    "\\end{align*}\n",
    "Perhaps it is more proper to say that the variance is $\\sigma(x(0), t)^2 \\mathbf I$, i.e., every component of the distribution is independent with variance $\\sigma(x(0), t)$. In any case, letting $k$ be the number of components, the density of a multivariate gaussian with mean $\\mu$ and independent components each having variance $\\sigma^2$ is given by\n",
    "$$\n",
    "(2 \\pi)^{-k/2} \\sigma^{-k} \\exp \\left(- \\frac{\\|x - \\mu \\|^2}{2 \\sigma^2} \\right).\n",
    "$$\n",
    "Taking the log and then gradient (with respect to $x$) of this, we get \n",
    "$$\n",
    "-(x-\\mu)/\\sigma^2.\n",
    "$$\n",
    "So we see that \n",
    "$$\n",
    " -\\nabla_x \\log(p_{0t}(x | x(0))) = (\\mu(x(0)) - x)/\\sigma(x(0))^2\n",
    " = x(0) \\frac{ \\exp\\left(-\\frac 1 4 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - \\frac 1 2 t \\beta_\\text{min}\\right)}{1 - \\exp \\left(-\\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - t \\beta_\\text{min}  \\right)}.\n",
    "$$\n",
    "At this point, we have everything we need for our loss function and, thus, everything to train a neural network to approximate the score function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we actually implement things, though, it's important to note that there are some issues when $t$ is very close to $0$. The root of the issue is that we do not actually have access to $p(0)$, but only a finite number of samples from it. When we approximate $\\mathbb E_{p_0(x)}$ by sampling from our dataset, what we are actually doing is replacing $p(0)$ by an average of delta distributions located at the points in our dataset. When as $t$ goes to $0$, the density $p_t$ becomes spiky, with spikes at the data points that blow up as $t$ goes to $0$. And the transition kernel $p_{0t}(x | x(0))$ also blows up, making its log gradient difficult to work with. To get around this, one can simply choose a small number $\\varepsilon$ and restrict all computation to $t \\in [\\varepsilon, 1]$, and sample from $p_\\varepsilon$ instead of $p_0$. A choice of $\\varepsilon = 10^{-5}$ is made for training, and $\\varepsilon = 10^{-3}$ for sampling (these numbers are again copied from the paper). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
