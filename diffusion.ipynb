{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to learn how to code a diffusion model. I'll use the following paper: https://arxiv.org/abs/2011.13456.\n",
    "\n",
    "The only real assumption which we make is that we have access to data which follows some distribution. The goal is to sample from this distribution.\n",
    "\n",
    "The basic idea is as follows. Given a (vector-valued) probability distribution, we can define a stochastic process whose initial conditions are sampled according to this distribution, and whose evolution is governed by the SDE\n",
    "$$\n",
    "dx = f(x, t)\\, dt + g(t) \\,dw,\n",
    "$$\n",
    "where $w$ is a standard Brownian motion and time ranges from $0$ to $T$. One can consider the case where $f$ and $g$ are matrix-valued and are both allowed to depend on $x$ as well as $t$, but we will just need the scalar case. If the marginal density of this stochastic process at time $t$ is given by $p_t$, then one can show that the time-reversal of this process also follows a (backwards-time) SDE:\n",
    "$$\n",
    "dx = (f(x, t) - g^2(t) \\nabla_x \\log p_t(x) )\\,dt + g(t) \\,d \\overline w,\n",
    "$$\n",
    "where $\\overline w$ is a Brownian motion when time runs backwards. The conclusion of this is that, if you know $f, g, \\nabla_x \\log p_t(x)$, and $p_T$, then you can numerically simulate the backwards SDE to sample from $p_0$. Typically, the setup is such that $p_0$ is the distribution we wish to sample from and $p_T$ is known and easy to sample from. This is usually accomplished by choosing $f$ and $g$ such that the evolution of the forward SDE converges to (at least very close to) a standard Gaussian, regardless of the initial condition. This leaves $\\nabla_x \\log p_t(x)$ (for all $t$) as the only unknown piece of the puzzle. This is the so-called score function, which is the critical ingredient needed to sample from the backwards SDE.\n",
    "\n",
    "There is also an associated probability flow ODE which has the property that, if the initial conditions are chosen according to $p_0$, then the marginal distributions of the process at time $t$ exactly match the marginal distributions of the SDE at time $t$, although the trajectories are different. So by sampling from $p_T$ and simulating the ODE backwards (which requires no more work than simulating it forwards), once can sample from $p_0$. The ODE is given by\n",
    "$$\n",
    "dx = (f(x, t) - g^2(t) \\nabla_x \\log p_t(x) )\\,dt.\n",
    "$$\n",
    "Again, the only missing ingredient is the score function $\\nabla_x \\log p_t(x)$.\n",
    "\n",
    "From this, we see that, apart from choosing $f$ and $g$, there are essentially two steps to training and doing inference with a diffusion model: learning the score function, and numerically solving either an SDE or ODE."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical machine learning approach is to use a neural network $s_\\theta(x, t)$ to approximate $\\nabla_x \\log p_t(x)$. The neural network must be a function of $x$ and $t$, as the score function is, and is parameterized by $\\theta$. The loss function is going to be weighted sum of\n",
    "$$\n",
    "\\| s_\\theta(x, t)- \\nabla_x \\log p_t(x)\\|^2\n",
    "$$\n",
    "evaluated at various choices of $x$ and $t$ (the norm is the $L^2$ norm, so this is the sum of squared errors). The exact weighting and choice of evaluation points can be considered a hyperparameter. It's also worth noting that $x$ and $t$ must be chosen in a way that makes evaluating $\\nabla_x \\log p_t(x)$ relatively easy. Indeed, it certainly must be difficult to evaluate it at arbitrary $x$ and $t$: if this were easy, there would be no need to learn a function $s_\\theta(x, t)$ approximating it.\n",
    "\n",
    "In general, working with the marginal density $p_t(x)$ is intractable, but the *conditional* marginal density, conditioned on initial value $x(0)$ of the SDE, may be easy to work with. We denote the conditional marginal density at time $t$, conditioned on the initial value $x(0)$, as $p_{0t}(x|x(0))$. In other words, $p_{0t}$ is the *transition kernel* from time $0$ to time $t$ of the stochastic process. If the choice of $f$ and $g$ are sufficiently nice, then this conditional marginal density is that of a Gaussian distribution whose mean and variance are a function of $x(0)$ and $t$. And the gradient of the log of this density is very easy to work with. \n",
    "\n",
    "I don't understand exactly the reasoning for the following. For fixed $t$, we want to minimize $\\mathbb E_{p_t(x)} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_t(x)\\|^2$, where the notation $\\mathbb E_{p_t(x)}$ means taking the expectation when $x$ is distributed according to $p_t(x)$. Since we know how to work with $p_{0t}(x | x(0))$ but not $p_t(x)$, we can instead minimize \n",
    "$$\n",
    "\\mathbb E_{p_0(x)} \\mathbb E_{p_{0t}(x | x(0))} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2.\n",
    "$$\n",
    "It is not obvious to me why minimizing this expression, where $p_t(x)$ has been replaced by $p_{0t}(x | x(0))$ (and a conditional expectation inserted), is equivalent to minimizing the original. It is, however, obvious that this problem is much more tractable. Lastly, we need to incorporate all time steps, so we can define our loss function as\n",
    "$$\n",
    "L(\\theta) = \\mathbb E_t \\lambda(t) \\mathbb E_{p_0(x)} \\mathbb E_{p_{0t}(x | x(0))} \\, \\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2,\n",
    "$$\n",
    "where $\\lambda(t)$ is a nonnegative function which determines the relative weights of the loss at different times, and $\\mathbb E_t$ has $t$ uniformly distributed between $0$ and $T$. Of course, we must take these expectations numerically. A simple scheme to do this is to sample $t$ uniformly, sample $x(0)$ from the data, sample $x$ from $p_{0t}(x|x(0))$, and evaluate $\\| s_\\theta(x, t)- \\nabla_x \\log p_{0t}(x | x(0)) \\|^2$ at this point. Average this over many such samples to get an estimate of $L(\\theta)$ which can be used for optimization. The paper says that it is typical to choose $\\lambda(t)$ to be inversely proportional to $\\mathbb E \\| \\nabla_x \\log p_{0t}(x(t) | x(0))\\|^2$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, things have been completely general. Let's choose specific hyperparameters so that we can simplify things further. Notably, we need to know $\\nabla_x \\log p_{0t}(x | x(0))$ to be able to do anything. We set $T=1$, so that $t$ ranges from $0$ to $1$, and we make the following choice of $f$ and $g$:\n",
    "\\begin{align*}\n",
    "f(x, t) &= \\beta(t),\\\\\n",
    "g(t) &= \\sqrt{\\beta(t)},\\\\\n",
    "\\end{align*}\n",
    "This is the continuous-time analog of the discrete-time *denoising diffusion probabilistic modeling* (DDPM) approach. It remains to choose $\\beta(t)$. We choose \n",
    "$$\\beta(t) = \\beta_\\text{min} + t(\\beta_\\text{max} - \\beta_\\text{min}).$$\n",
    "So $\\beta(t)$ moves linearly from $\\beta_\\text{min}$ to $\\beta_\\text{max}$. And we will choose $\\beta_\\text{min}=0.1$, $\\beta_\\text{max}=20$. These are simply the choices made in the paper I am following, and I do not have any extra insight as to why these choices are are made. The main paper gives the following reference for how the mean and variance of the transition kernel can be computed: Applied stochastic differential equations, volume 10, by Simo Sarkka and Arno Solin.\n",
    "We can obtain the following transition kernels: $p_{0t}(x|x(0))$ is a Gaussian distribution with mean and variance \n",
    "\\begin{align*}\n",
    "\\mu(x(0), t) &= x(0) \\, \\exp\\left(-\\frac 1 4 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - \\frac 1 2 t \\beta_\\text{min}\\right), \\\\\n",
    "\\sigma(x(0), t)^2 &= 1 - \\exp \\left(-\\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - t \\beta_\\text{min}  \\right).\n",
    "\\end{align*}\n",
    "Perhaps it is more proper to say that the variance is $\\sigma(x(0), t)^2 \\mathbf I$, i.e., every component of the distribution is independent with variance $\\sigma(x(0), t)$. In any case, letting $k$ be the number of components, the density of a multivariate gaussian with mean $\\mu$ and independent components each having variance $\\sigma^2$ is given by\n",
    "$$\n",
    "(2 \\pi)^{-k/2} \\sigma^{-k} \\exp \\left(- \\frac{\\|x - \\mu \\|^2}{2 \\sigma^2} \\right).\n",
    "$$\n",
    "Taking the log and then gradient (with respect to $x$) of this, we get \n",
    "$$\n",
    "-(x-\\mu)/\\sigma^2.\n",
    "$$\n",
    "So we see that \n",
    "\\begin{align*}\n",
    "\\nabla_x \\log(p_{0t}(x | x(0))) &= (\\mu(x(0), t) - x)/\\sigma(x(0), t)^2\\\\\n",
    " &= \\frac{ x(0) \\exp\\left(-\\frac 1 4 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - \\frac 1 2 t \\beta_\\text{min}\\right) - x}{1 - \\exp \\left(-\\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) - t \\beta_\\text{min}  \\right)}\\\\\n",
    " &= \\frac{x(0) e^{-\\alpha(t)/2}-x}{1-e^{-\\alpha(t)}},\n",
    "\\end{align*}\n",
    "for $\\alpha(t) = \\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) + t \\beta_\\text{min}$.\n",
    "\n",
    "Lastly, we need $\\lambda(t)$. We can compute \n",
    "\\begin{align*}\n",
    "\\mathbb E \\| \\nabla_x \\log p_{0t}(x(t) | x(0))\\|^2\n",
    "&= \\mathbb E \\| (x(t) - \\mu(x(0), t))/(\\sigma(t)^2) \\|^2\\\\\n",
    "&= \\frac{1}{\\sigma(t)^2} \\mathbb E \\,  \\mathbb E \\left[ \\frac{x(t) - \\mu(x(0), t)}{\\sigma(t)} \\,  \\Bigr| \\, x(0) \\right]. \n",
    "\\end{align*}\n",
    "Conditional on $x(0)$, $x(t)$ follows a normal distribution with mean $\\mu(x(0), t)$ and standard deviation $\\sigma(t)$, so the inner expectation is just the second moment of a standard normal distribution, which is $1$. The outer expectation does nothing, and we are left with\n",
    "$$\n",
    "\\lambda(t) = \\frac{1}{\\sigma(t)^2}.\n",
    "$$\n",
    "\n",
    "At this point, we have everything we need for our loss function and, thus, everything to train a neural network to approximate the score function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we actually implement things, though, it's important to note that there are some issues when $t$ is very close to $0$. The root of the issue is that we do not actually have access to $p(0)$, but only a finite number of samples from it. When we approximate $\\mathbb E_{p_0(x)}$ by sampling from our dataset, what we are actually doing is replacing $p(0)$ by an average of delta distributions located at the points in our dataset. When as $t$ goes to $0$, the density $p_t$ becomes spiky, with spikes at the data points that blow up as $t$ goes to $0$. And the transition kernel $p_{0t}(x | x(0))$ also blows up, making its log gradient difficult to work with. To get around this, one can simply choose a small number $\\varepsilon$ and restrict all computation to $t \\in [\\varepsilon, 1]$, and sample from $p_\\varepsilon$ instead of $p_0$. A choice of $\\varepsilon = 10^{-5}$ is made for training, and $\\varepsilon = 10^{-3}$ for sampling (these numbers are again copied from the paper). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a brief plan of the things to be implemented. For the toy example, we need data. An easy option is to just use a mixture of Gaussians. We'll make a abstract data generator class for this and subclass a Gaussian mixture data generator. We'll use the PyTorch built-in `dataset` and/or `dataloader` classes for feeding our training data to the model. For the model, we'll need a neural network which will approximate our score function, a choice of $f$ and $g$, and a way to train the model. We can make a class for the score function neural network. Another class can deal with $f, g, \\beta_\\text{min}, \\beta_\\text{max}$, and $\\nabla_x \\log(p_{0t}(x | x(0)))$, and the model trainer can be a class. Finally, we'll need a numerical ODE/SDE solver which can take the trained score function and generate samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from abc import ABC # abstract base class\n",
    "import abc\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Type\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(ABC):\n",
    "    @abc.abstractmethod\n",
    "    def generate_sample(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GaussianMixtureGenerator(DataGenerator):\n",
    "    def __init__(self, num_dims, weights, means, covariances):\n",
    "        self.num_dims = num_dims\n",
    "        self.num_gaussians = len(weights)\n",
    "        self.indexes = list(range(self.num_gaussians))\n",
    "        self.weights = weights\n",
    "        self.means = means\n",
    "        self.covariances = covariances\n",
    "        assert(len(means) == self.num_gaussians)\n",
    "        assert(len(covariances) == self.num_gaussians)\n",
    "\n",
    "    def generate_sample(self):\n",
    "        mixture_class = np.random.choice(self.indexes, p=self.weights)\n",
    "        return np.random.multivariate_normal(mean=self.means[mixture_class], cov=self.covariances[mixture_class])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, our neural network for the score function. Remember that the score function is a function with $x$ and $t$ as inputs, and a vector (with the dimensions of $x$) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreModel(nn.Module):\n",
    "    def __init__(self, num_dims: int, num_hidden_layers: int, hidden_layer_size: int, activation: Type[nn.Module]=nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.num_dims = num_dims\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        assert (num_hidden_layers >= 1) # require a hidden layer\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.activation = activation() # an instance of the class\n",
    "        self.first_layer = nn.Linear(in_features=num_dims+1, # an extra time dimension\n",
    "                                     out_features=hidden_layer_size)\n",
    "        self.inner_layers = [nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "                             for _ in range(num_hidden_layers-1)]\n",
    "        self.final_layer = nn.Linear(in_features=hidden_layer_size,\n",
    "                                     out_features=num_dims)\n",
    "\n",
    "    def forward(self, x, t): # remember that x and t have shape (batch, dim) and (batch, 1)\n",
    "        input = torch.cat((x, t), dim=1)\n",
    "        out = self.first_layer(input)\n",
    "        out = self.activation(out)\n",
    "        for layer in self.inner_layers:\n",
    "            out = layer(out)\n",
    "            out = self.activation(out)\n",
    "        return self.final_layer(out)       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement the class which holds $f$, $g$, and related values which are necessary for training. We'll call such choices *noise schemes*. They control how the noise added to the data. We make the assumption that time goes from $0$ to $1$. We implement the continuous analog of the DDPM (denoising diffusion probabilistic modeling) noise scheme. Remember that DDPM has $f(x, t) = \\beta(t)$ and $g(t) = \\sqrt{\\beta(t)}$. A linear choice of $\\beta(t)$ is $\\beta(t) = \\beta_\\text{min} + t(\\beta_\\text{max} - \\beta_\\text{min})$. This gives $\\nabla_x \\log(p_{0t}(x | x(0))) = -\\frac{x(0) e^{-\\alpha(t)/2}-x}{1-e^{-\\alpha(t)}}$ for $\\alpha(t) = \\frac 1 2 t^2 (\\beta_\\text{max}-\\beta_\\text{min}) + t \\beta_\\text{min}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseScheme(ABC):\n",
    "    @abc.abstractmethod\n",
    "    def f(self, x, t):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def g(self, x, t):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def conditional_log_gradient(self, x, t, x_0):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def generate_noised_sample(x, t, x_0):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class LinearDDPMNoiseScheme(NoiseScheme):\n",
    "    def __init__(self, beta_min=0.1, beta_max=20):\n",
    "        self.beta_min = beta_min\n",
    "        self.beta_max = beta_max\n",
    "\n",
    "    def beta(self, t):\n",
    "        return self.beta_min + t*(self.beta_max - self.beta_min)\n",
    "\n",
    "    def f(self, x, t):\n",
    "        return self.beta(t)\n",
    "\n",
    "    def g(self, x, t):\n",
    "        return torch.sqrt(self.beta(t))\n",
    "    \n",
    "    def alpha(self, t):\n",
    "        return 1/2*torch.square(t)*(self.beta_max - self.beta_min) + t*self.beta_min\n",
    "\n",
    "    def conditional_mean(self, t, x_0):\n",
    "        return x_0*torch.exp(-self.alpha(t)/2)\n",
    "\n",
    "    def conditional_variance(self, t):\n",
    "        return 1-torch.exp(-self.alpha(t))\n",
    "    \n",
    "    def conditional_log_gradient(self, x, t, x_0):\n",
    "        return (self.conditional_mean(t, x_0) - x)/self.conditional_variance(t)\n",
    "    \n",
    "    def generate_noised_sample(self, t, x_0):\n",
    "        var = self.conditional_variance(t) # shape is (batch, 1)\n",
    "        std = torch.sqrt(var)\n",
    "        std = std.expand(x_0.size())  # expands to (batch, dim)\n",
    "        mean = self.conditional_mean(t, x_0) # shape is (batch, dim)\n",
    "        return torch.normal(mean, std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, a trainer class. A trainer will need to be able to take in data, an untrained score neural network, and a noise scheme and train the neural network on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionTrainer:\n",
    "    def __init__(self, \n",
    "                 score: ScoreModel,\n",
    "                 noise_scheme: NoiseScheme, \n",
    "                 train_dataset: Dataset,\n",
    "                 time_weight: Callable[[float], float], # a function from R to R, the weights $\\lambda(t)$ of each time\n",
    "                 train_epsilon=0.00001,\n",
    "                 optimizer: Type[torch.optim.Optimizer]=torch.optim.Adam, # should take a class, not an instance\n",
    "                 batch_size=32,\n",
    "                 epochs=1000,\n",
    "                 ) -> None:\n",
    "        self.score = score\n",
    "        self.noise_scheme = noise_scheme\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dataloader = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        self.time_weight = time_weight\n",
    "        self.train_epsilon = train_epsilon\n",
    "        self.optimizer = optimizer(params=self.score.parameters())\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train_one_batch(self, batch) -> None:\n",
    "        ...\n",
    "        # generate random times\n",
    "\n",
    "    def train_one_epoch(self) -> None:\n",
    "        for batch in self.dataloader:\n",
    "            self.train_one_batch(batch)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        for epoch in range(self.epochs):\n",
    "            self.train_one_epoch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need some sort of numerical integrator to solve the ODE/SDE. Here, I implement a very basic Euler method for the probability flow ODE. Remember that the ODE is given by \n",
    "$$\n",
    "dx = (f(x, t) - g^2(t) \\nabla_x \\log p_t(x) )\\,dt.\n",
    "$$\n",
    "This ODE will be simulated backwards for sampling, starting at time 1, and going to time 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EulerODESampler: # numerically integrates\n",
    "    def __init__(self, score: ScoreModel, noise_scheme: NoiseScheme, sample_epsilon=0.001, num_steps=30):\n",
    "        self.score = score\n",
    "        self.num_dims = self.score.num_dims\n",
    "        self.noise_scheme = noise_scheme\n",
    "        self.sample_epsilon = sample_epsilon\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "    def generate_latent():\n",
    "        ...\n",
    "\n",
    "    def step(x, t):\n",
    "        ...\n",
    "\n",
    "    def generate_sample():\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING that things don't raise errors. Some testing library would be better but this is fine.\n",
    "\n",
    "# testing data generator\n",
    "num_dims=2\n",
    "num_classes=4\n",
    "num_datapoints = 32*500\n",
    "identity_covariance = np.identity(num_dims)\n",
    "covariances = [identity_covariance]*num_classes\n",
    "means = [(0, 0), (1, 0), (0, 1), (2, -3)]\n",
    "weights = [.3, .1, .25, .35]\n",
    "data_generator = GaussianMixtureGenerator(\n",
    "    num_dims=num_dims, weights=weights, means=means, covariances=covariances)\n",
    "\n",
    "data_sample = data_generator.generate_sample()\n",
    "data = torch.Tensor(np.array([data_generator.generate_sample() for _ in range(num_datapoints)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing score model\n",
    "score = ScoreModel(num_dims=num_dims, num_hidden_layers=2, hidden_layer_size=30, activation=torch.nn.ReLU)\n",
    "x = torch.Tensor([\n",
    "    [1.3, 2]\n",
    "])\n",
    "t = torch.Tensor([\n",
    "    [.5]\n",
    "])\n",
    "score(x, t)\n",
    "\n",
    "# testing noise scheme\n",
    "x_0 = torch.zeros_like(x)\n",
    "noise_scheme = LinearDDPMNoiseScheme()\n",
    "noise_scheme.f(x, t)\n",
    "noise_scheme.g(x, t)\n",
    "noise_scheme.conditional_log_gradient(x, t, x_0)\n",
    "noise_scheme.generate_noised_sample(t, x_0)\n",
    "\n",
    "# testing the trainer\n",
    "dataset = torch.utils.data.dataset.TensorDataset(data)\n",
    "trainer = DiffusionTrainer(score=score,\n",
    "                           noise_scheme=noise_scheme,\n",
    "                           train_dataset=dataset,\n",
    "                           epochs=5)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdebenchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
